{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb43bfdf-89ca-4cd3-9cb6-5cc47cedad96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = \"/mnt/swordfish-pool2/harsha\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40298df9-c315-48e6-b0f5-b29728816839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu' \n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer,RobertaConfig\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset,load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2055075-eb5d-4571-8c2c-ce973240392d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/home/hv2237/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Found cached dataset glue (/home/hv2237/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Found cached dataset glue (/home/hv2237/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset('glue', 'sst2', split='train')\n",
    "val_dataset = load_dataset('glue', 'sst2', split='validation')\n",
    "test_dataset = load_dataset('glue', 'sst2', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcefa30d-78b7-41bb-b5ab-6688bc6b32e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/hv2237/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-134b5ffdd978af4d.arrow\n",
      "Loading cached processed dataset at /home/hv2237/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-fd93ca5f7ad2a80f.arrow\n",
      "Loading cached processed dataset at /home/hv2237/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-3232f58e26d7662d.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
    "val_dataset = val_dataset.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
    "test_dataset = test_dataset.map(lambda examples: {'labels': examples['label']}, batched=True)\n",
    "val_dataset = val_dataset.remove_columns(['label'])\n",
    "test_dataset = test_dataset.remove_columns(['label'])\n",
    "train_dataset = train_dataset.remove_columns(['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cbbb7d5-434d-4a8b-8af1-ae6d139947d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240ce834d6ad47b9b2e2acc1ccc7ac21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432a644cdaf44af8891ea7733797bd06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0109772120b14d44ad741dac48290a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a12aec709a45d4bd226749190ed5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained('roberta-large')\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a61db1e3-2452-48fc-a4b6-ceeb5ab30699",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 128\n",
    "train_dataset = train_dataset.map(lambda e: tokenizer(e['sentence'], truncation=True, padding='max_length', max_length=MAX_LENGTH), batched=True)\n",
    "val_dataset = val_dataset.map(lambda e: tokenizer(e['sentence'], truncation=True, padding='max_length', max_length=MAX_LENGTH), batched=True)\n",
    "test_dataset = test_dataset.map(lambda e: tokenizer(e['sentence'], truncation=True, padding='max_length', max_length=MAX_LENGTH), batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "484347a5-84b6-4676-ab72-458220e1b2dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "val_dataset.set_format(type='torch', columns=['input_ids',  'attention_mask', 'labels'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids',  'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b8cfa07-6195-46e7-b363-12eda5045beb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c7e13f-0a2e-4cc4-a35e-a533f871ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='/mnt/swordfish-pool2/harsha/KD',          #output directory\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=5,              \n",
    "    per_device_train_batch_size=32,                #batch size per device during training\n",
    "    per_device_eval_batch_size=32,                #batch size for evaluation\n",
    "    logging_dir='/mnt/swordfish-pool2/harsha/logs',            \n",
    "    logging_steps=100,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    no_cuda=False,\n",
    "    load_best_model_at_end=True,\n",
    "    # eval_steps=100,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=val_dataset,            \n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "train_out = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3c1ed94-0a04-4886-9919-6afc0d8c9621",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=16) #prepare dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e66a7c6b-34d1-4e1d-9a70-2235e59b59ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_dataloader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b1ebca0-6221-4342-a1c8-c98d584630bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import textbrewer\n",
    "from textbrewer import GeneralDistiller\n",
    "from textbrewer import TrainingConfig, DistillationConfig\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8add369d-048b-43df-a7c4-e2fd0d679e39",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "roberta_mini = RobertaConfig.from_pretrained('philschmid/roberta-large-sst2')\n",
    "roberta_mini.num_hidden_layers = 3\n",
    "roberta_mini.output_hidden_states = True\n",
    "\n",
    "student_model = RobertaForSequenceClassification(roberta_mini) #, num_labels = 2\n",
    "student_model.to(device=device)\n",
    "\n",
    "\n",
    "# bert_config = BertConfig.from_json_file('/content/drive/MyDrive/TextBrewer-master/examples/student_config/bert_base_cased_config/bert_config.json')\n",
    "# bert_config.output_hidden_states = True\n",
    "# teacher_model = BertForSequenceClassification(bert_config) #, num_labels = 2\n",
    "# teacher_model.load_state_dict(torch.load('/content/drive/MyDrive/sst2_teacher_model.pt'))\n",
    "teacher_model = RobertaForSequenceClassification.from_pretrained('philschmid/roberta-large-sst2', output_hidden_states=True)\n",
    "teacher_model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0709c2-7cd2-4c66-b4ea-2d300d16a213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "num_training_steps = len(train_dataloader) * num_epochs\n",
    "# Optimizer and learning rate scheduler\n",
    "optimizer = AdamW(student_model.parameters(), lr=1e-4)\n",
    "\n",
    "scheduler_class = get_linear_schedule_with_warmup\n",
    "# arguments dict except 'optimizer'\n",
    "scheduler_args = {'num_warmup_steps':int(0.1*num_training_steps), 'num_training_steps':num_training_steps}\n",
    "\n",
    "\n",
    "def simple_adaptor(batch, model_outputs):\n",
    "    return {'logits': model_outputs.logits, 'hidden': model_outputs.hidden_states}\n",
    "\n",
    "distill_config = DistillationConfig(\n",
    "    intermediate_matches=[    \n",
    "     {'layer_T':0, 'layer_S':0, 'feature':'hidden', 'loss': 'hidden_mse','weight' : 1},\n",
    "     {'layer_T':6, 'layer_S':2, 'feature':'hidden', 'loss': 'hidden_mse','weight' : 1}])\n",
    "train_config = TrainingConfig()\n",
    "\n",
    "distiller = GeneralDistiller(\n",
    "    train_config=train_config, distill_config=distill_config,\n",
    "    model_T=teacher_model, model_S=student_model, \n",
    "    adaptor_T=simple_adaptor, adaptor_S=simple_adaptor)\n",
    "\n",
    "\n",
    "with distiller:\n",
    "    distiller.train(optimizer, train_dataloader, num_epochs, scheduler_class=scheduler_class, scheduler_args = scheduler_args, callback=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2f4849f-81f3-47d4-8f6e-dee97f1ab3b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import evaluate\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/mnt/swordfish-pool2/harsha/hpml',          #output directory\n",
    "    # learning_rate=1e-4,\n",
    "    # num_train_epochs=50,              \n",
    "    # per_device_train_batch_size=8,                #batch size per device during training\n",
    "    per_device_eval_batch_size=16,                #batch size for evaluation\n",
    "    # logging_dir='/content/drive/MyDrive/logs',            \n",
    "    # logging_steps=100,\n",
    "    # do_train=True,\n",
    "    do_eval=True,\n",
    "    no_cuda=False,\n",
    "    # load_best_model_at_end=True,\n",
    "    # save_strategy=\"epoch\",\n",
    "    # # eval_steps=100,\n",
    "    # metric_for_best_model = 'eval_loss',\n",
    "    # evaluation_strategy=\"epoch\"\n",
    ")\n",
    "acc = evaluate.load(\"accuracy\")\n",
    "import numpy as np\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels,  = eval_pred\n",
    "    # print(logits)\n",
    "    logits = logits[0]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc.compute(predictions=predictions, references=labels),\n",
    "        # 'precision': prec.compute(predictions=predictions, references=labels),\n",
    "        # 'recall': rec.compute(predictions=predictions, references=labels),\n",
    "        # 'f1': f1.compute(predictions=predictions, references=labels)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e30753-0ee8-406f-b1a7-8ee73fde2370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "        model=student_model,  # the instantiated ðŸ¤— Transformers model to be trained\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "trainer.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e01a4d-51b8-40f6-a668-bbf01a699d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "        model=teacher_model,  # the instantiated ðŸ¤— Transformers model to be trained\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "trainer.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16dd5396-f2d4-4526-9ddb-00d9f45577f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LAYER NAME       \t        #PARAMS\t     RATIO\t MEM(MB)\n",
      "--model:         \t    355,362,308\t   100.00%\t 1355.60\n",
      "  --roberta:     \t    354,310,658\t    99.70%\t 1351.59\n",
      "    --embeddings:\t     52,001,282\t    14.63%\t  198.37\n",
      "    --encoder:   \t    302,309,376\t    85.07%\t 1153.22\n",
      "  --classifier:  \t      1,051,650\t     0.30%\t    4.01\n",
      "    --dense:     \t      1,049,600\t     0.30%\t    4.00\n",
      "    --out_proj:  \t          2,050\t     0.00%\t    0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary(teacher_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "147ec8cb-a25c-475f-b4fe-e7fb0c651ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LAYER NAME       \t        #PARAMS\t     RATIO\t MEM(MB)\n",
      "--model:         \t     90,841,604\t   100.00%\t  346.54\n",
      "  --roberta:     \t     89,789,954\t    98.84%\t  342.52\n",
      "    --embeddings:\t     52,001,282\t    57.24%\t  198.37\n",
      "    --encoder:   \t     37,788,672\t    41.60%\t  144.15\n",
      "  --classifier:  \t      1,051,650\t     1.16%\t    4.01\n",
      "    --dense:     \t      1,049,600\t     1.16%\t    4.00\n",
      "    --out_proj:  \t          2,050\t     0.00%\t    0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(summary(student_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a19a7d6-635c-4358-b5f4-a4c938276212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
